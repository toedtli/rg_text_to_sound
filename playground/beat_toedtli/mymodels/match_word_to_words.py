# -*- coding: utf-8 -*-
"""match_word_to_words.ipynb

Automatically generated by Colaboratory, then edited by B.Tödtli.

Original file is located at
    https://colab.research.google.com/drive/1n3Zc5kbv8sH6DvuqXGxN3CmbGv8r0tJl
"""

import spacy
import numpy as np
from sklearn.cluster import KMeans

#!python -m spacy download en_core_web_lg

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/rg_text_to_sound/tts_pipeline/src/

from tts_pipeline.core import InferenceModel
class word_to_words_matcher(InferenceModel):
  def build(self,target_words):
    self.target_tokens = np.array(target_words)
    self.nlp = spacy.load('en_core_web_lg')
    vector_array = self.get_vector_array(target_tokens_list)

    self.clusterer = KMeans(n_clusters=vector_array.shape[0],init='random')
    self.clusterer.cluster_centers_ = vector_array

  def get_vector_array(self,word_list,verbose=False):
    docstr = " ".join(word_list)
    target_tokens_doc = self.nlp(docstr)
    vector_list = []
    for token in target_tokens_doc:
        if verbose:
          print(token.text, token.has_vector, token.vector_norm, token.is_oov)
        vector_list.append(token.vector)
    return np.array(vector_list)

  def match_word_to_words(new_word):
    vector_array = self.get_vector_array(words)
    return clusterer.predict(vector_array.reshape(1,-1))
  
  def predict(self,words):
    vector_array = self.get_vector_array(words)
    clusterind = self.clusterer.predict(vector_array)
    return self.target_tokens[clusterind].tolist()
  
  def dispose(self):
    del self.nlp

def test_word_to_words_matcher():
    """
    Code that might later be used to create tests.
    """
    target_words = ['slow', 'quick', 'yellow', 'loud', 'hard']
    wwm = word_to_words_matcher()
    wwm.build(target_words)

    wwm.predict(target_words)

    wwm.predict(['rigid','stiff']).tolist()

    """# Test the matching on synsets of the target words:"""

    import nltk
    nltk.download('wordnet')
    from nltk.corpus import wordnet

    def get_synonyms(word):
      synonyms = []
      for syn in wordnet.synsets(word):
          for lm in syn.lemmas():
                  synonyms.append(lm.name())
      return set(synonyms)

    ','.join(wwm.predict(get_synonyms('quick')))

    from collections import defaultdict
    good_dict = bad_dict=defaultdict(list)

    for target_word in target_words:
      for word in get_synonyms(target_word):
        prediction = wwm.predict([word])[0]
        if prediction==target_word:
          #print(f'{word}->{target_word}:ok!')
          good_dict[target_word]+=[word]
        else:
          #print(word,':',f'{prediction} (should be {target_word})')
          bad_dict[target_word]+=[word]

    print('synset words that were not mapped back to the target word:')
    for key,val in bad_dict.items():
      print(key,val)

    print('synset words that were correctly mapped back to the target word:')
    for key,val in good_dict.items():
      print(key,val)

